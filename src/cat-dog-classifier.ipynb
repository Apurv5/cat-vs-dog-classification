{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat Dog Classification\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn\n",
    "from tensorflow.contrib.learn import RunConfig as run_config\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function\n",
    "Image reader, Input pipeline, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAT = 0\n",
    "DOG = 1\n",
    "IS_LOW_MEMORY_MODE = True\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_file():\n",
    "  file_list = ['train', 'test']\n",
    "  valid = True\n",
    "\n",
    "  for i in range(len(file_list)):\n",
    "    filename = file_list[i] + '.zip'\n",
    "    dest_filename = os.path.join(cwd, 'data', filename)\n",
    "\n",
    "    if not os.path.exists(dest_filename):\n",
    "      print('Please download ' + filename + ' and put on src/data folder')\n",
    "      url = \"https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/\"\n",
    "      print(url + filename)\n",
    "      valid = False\n",
    "      continue\n",
    "    \n",
    "    images_path = os.path.join(cwd, 'data', filename)\n",
    "\n",
    "    zip = zipfile.ZipFile(dest_filename)\n",
    "    if not os.path.exists(images_path):\n",
    "        print('Extracting...')\n",
    "        zip.extractall(os.path.join(cwd, 'data'))\n",
    "      \n",
    "  return valid\n",
    "\n",
    "def read_image_label_list(folder_dir):\n",
    "    dir_list = os.listdir(os.path.join(cwd, folder_dir))\n",
    "    \n",
    "    filenames = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, d in enumerate(dir_list):\n",
    "        if re.search(\"train\", folder_dir):\n",
    "            if re.search(\"cat\", d):\n",
    "                labels.append(CAT)\n",
    "            else:\n",
    "                labels.append(DOG)\n",
    "        else:\n",
    "            labels.append(-1)\n",
    "        filenames.append(os.path.join(cwd, folder_dir, d))\n",
    "    \n",
    "    return filenames, labels\n",
    "\n",
    "def read_images_from_disk(input_queue):\n",
    "    filename = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    \n",
    "    file_contents = tf.read_file(filename)\n",
    "    image = tf.image.decode_image(file_contents, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def gen_input_fn(image_list, label_list, batch_size, shuffle):\n",
    "    \n",
    "    def input_fn():\n",
    "        images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
    "        labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "\n",
    "        input_queue = tf.train.slice_input_producer(\n",
    "            [images, labels],\n",
    "            capacity=batch_size * 5,\n",
    "            shuffle=shuffle,\n",
    "            name=\"file_input_queue\"\n",
    "        )\n",
    "\n",
    "        image, label = read_images_from_disk(input_queue)\n",
    "\n",
    "        image = tf.image.resize_images(image, (224, 224), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "        image_batch, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=1,\n",
    "            name=\"batch_queue\",\n",
    "            capacity=batch_size * 10,\n",
    "            allow_smaller_final_batch=False\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            tf.identity(image_batch, name=\"features\"), \n",
    "            tf.identity(label_batch, name=\"label\")\n",
    "        )\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "def train_valid_input_fn(data_dir, batch_size):\n",
    "    img, labels = read_image_label_list(data_dir)\n",
    "    img = np.array(img)\n",
    "    labels = np.array(labels)\n",
    "    data_size = img.shape[0]\n",
    "\n",
    "    print(\"Data size: \" + str(data_size))\n",
    "    split = int(0.7 * data_size)\n",
    "\n",
    "    random_seq = np.random.permutation(data_size)\n",
    "\n",
    "    img = img[random_seq]\n",
    "    labels = labels[random_seq]\n",
    "\n",
    "    return (\n",
    "        gen_input_fn(img[0:split], labels[0:split], batch_size, shuffle = True),\n",
    "        gen_input_fn(img[split:], labels[split:], batch_size, shuffle = False)\n",
    "    )\n",
    "\n",
    "def test_input_fn(data_dir, batch_size, shuffle):\n",
    "    image_list, label_list = read_image_label_list(data_dir)\n",
    "    return gen_input_fn(image_list, label_list, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Data\n",
    "Check correctness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_file():\n",
    "    print \"Files are ready \\o/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_img(data, label=None):\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.imshow(data)\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "\n",
    "def preview_img():\n",
    "    \n",
    "    img_preview = tf.Graph()\n",
    "    \n",
    "    with img_preview.as_default():\n",
    "        tensor_train, _ = train_valid_input_fn('data/train', batch_size=5)\n",
    "        result = tf.tuple(tensor_train())\n",
    "        \n",
    "    with tf.Session(graph=img_preview) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        images, labels = sess.run(result)\n",
    "        for i in range(len(images)):\n",
    "            plot_img(images[i], str(labels[i]))\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "        sess.close()\n",
    "\n",
    "preview_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "Create a VGG19 model for using in Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_19(inputs, is_training):\n",
    "    with tf.variable_scope('vgg_19', values=[inputs]):\n",
    "        with slim.arg_scope(\n",
    "            [slim.conv2d, slim.fully_connected],\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "            weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "            \n",
    "            net = inputs\n",
    "        \n",
    "            if IS_LOW_MEMORY_MODE == False:\n",
    "                net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "\n",
    "                net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "\n",
    "                net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "\n",
    "                net = tf.reshape(net, [-1, 7 * 7 * 512])\n",
    "\n",
    "                net = slim.fully_connected(net, 2048, scope='fc6')\n",
    "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout6')\n",
    "\n",
    "                net = slim.fully_connected(net, 2048, scope='fc7')\n",
    "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout7')\n",
    "\n",
    "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc8')\n",
    "                \n",
    "            else:\n",
    "                # Model for my Mac T_T\n",
    "                net = tf.image.resize_images(net, (72, 72), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "                \n",
    "                net = slim.repeat(net, 1, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "                \n",
    "                net = slim.repeat(net, 1, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "                \n",
    "                net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "                \n",
    "                net = tf.reshape(net, [-1, 9 * 9 * 256])\n",
    "                \n",
    "                net = slim.fully_connected(net, 1024, scope='fc4')\n",
    "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout4')\n",
    "\n",
    "                net = slim.fully_connected(net, 1024, scope='fc5')\n",
    "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout5')\n",
    "\n",
    "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc6')\n",
    "            \n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_model_fn(features, labels, mode, params):\n",
    "    \n",
    "    is_training = False\n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        is_training = True\n",
    "        \n",
    "    output = vgg_19(features, is_training)\n",
    "    \n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    \n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        onehot_labels = tf.one_hot(\n",
    "            tf.cast(labels, tf.int32), \n",
    "            depth = 2\n",
    "        )\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels = onehot_labels,\n",
    "            logits = output \n",
    "        )\n",
    "        \n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss = loss,\n",
    "            global_step = tf.contrib.framework.get_global_step(),\n",
    "            learning_rate = params['learning_rate'],\n",
    "            optimizer = \"Adam\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    classes_predictions = tf.argmax(output, axis = 1, name = \"classes_tensor\")\n",
    "    accuracy_metric = tf.identity(\n",
    "        tf.metrics.accuracy(labels, classes_predictions)[1],\n",
    "        name = \"accuracy_tensor\"\n",
    "    )\n",
    "    predictions = {\n",
    "        \"classes\": classes_predictions,\n",
    "        \"probabilities\": tf.nn.softmax(output, name = \"softmax_tensor\"),\n",
    "        \"accuracy\": accuracy_metric\n",
    "    }\n",
    "    \n",
    "    if mode == learn.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": accuracy_metric\n",
    "        }\n",
    "    \n",
    "    return model_fn.ModelFnOps(\n",
    "        mode = mode,\n",
    "        predictions = predictions,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metric_ops = eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 25000\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering_fn(features, labels):\n",
    "    features = tf.to_float(features)\n",
    "    features = tf.map_fn(tf.image.per_image_standardization, features)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model_path = '_model/vgg_low' if IS_LOW_MEMORY_MODE else '_model_vgg'\n",
    "classifier = learn.Estimator(\n",
    "    model_fn = vgg_model_fn, \n",
    "    model_dir = model_path,\n",
    "    config = run_config(\n",
    "        save_summary_steps = 10,\n",
    "        keep_checkpoint_max = 3,\n",
    "        save_checkpoints_steps = 100\n",
    "    ),\n",
    "    feature_engineering_fn = feature_engineering_fn,\n",
    "    params = {\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    ")\n",
    "\n",
    "train_input_fn, validate_input_fn = train_valid_input_fn('data/train', 32)\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors = {\n",
    "        \"accuracy\": \"accuracy_tensor\"\n",
    "    }, \n",
    "    every_n_iter = 3\n",
    ")\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    input_fn = validate_input_fn,\n",
    "    eval_steps = 20,\n",
    "    every_n_steps = 50,\n",
    "    name = 'Validatation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let it's trainnnn !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into _model/vgg_low/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.693155, step = 1\n",
      "INFO:tensorflow:accuracy = 0.4375\n",
      "INFO:tensorflow:accuracy = 0.484375 (13.656 sec)\n",
      "INFO:tensorflow:accuracy = 0.458333 (8.550 sec)\n",
      "INFO:tensorflow:accuracy = 0.429688 (8.258 sec)\n",
      "INFO:tensorflow:accuracy = 0.45 (9.074 sec)\n",
      "INFO:tensorflow:accuracy = 0.447917 (9.140 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-90112bd53258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmonitors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlogging_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_monitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m       \u001b[0msummary_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryWriterCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "classifier.fit(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 8000,\n",
    "    monitors = [logging_hook, validation_monitor]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
